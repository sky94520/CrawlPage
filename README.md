# 专利页面[非详情页]爬虫
>针对知网专利，本代码由两部分组成:
>第一部分是根据条件爬取符合条件的专利列表；
>第二部分则是根据第一个部分得到的专利列表爬取具体的专利。
>此为第一部分。
>相关说明<br>
>1. run_page.py 负责启动爬虫；
>2. 本爬虫使用了redis作为断点保存和队列；
>3. 当某一块爬取完成后，page爬虫检查队列是否有数据，有则设置断点，并开始爬取
>4. 使用到.env，用于区别测试环境和生产环境，以此使得二者分开，便于调试。爬取规则放入配置文件.env中
>5. 知网的搜索条件是得到cookie，相同的搜索条件对应的cookie是相同的;当出现验证码的时候进行重新请求cookie即可（也可以进行识别）
## 思路
>run_page.py会根据redis中队列中的数据(主分类号、申请人)，从中取出一个进行爬取。
>而在开启爬虫时，启动器会检测redis是否存在一个名称为process的字典，以此来确定从哪启动。
>爬虫在每次抓取页面成功后，会保存页面并解析页面，它也会判断当前的页面的专利个数。
>简而言之，run_page.py会先确认redis中的process是否已经爬取完成，如果爬取完成，那么会从redis队列中取出一个类别，并进行爬取
## 文件命名规范
>列表页命名 文件夹为redis中队列的数据(主分类好、申请人)，文件名为页码(按照年份爬取的页面依次递增)
## 问题
>当某一类别的数据超过6000个时，则只能获取6000个数据，当前的办法是按照公开日进行
>拆分，在cookie中添加date_gkr_from date_gkr_to两个字段。
>目前会出现两种情况，第一种是小于6000个值的，此时不需要拆分，直接进行即可;
>第二种是大于6000的则按照天数拆分，默认的天数为366天（不超过一年），当超过6000时，
>先尝试使用一年（根据timedelta(days=366)），之后days递减

## 所需外部环境
>###redis
>本爬虫使用了redis作为队列使用，爬虫启动时，会先判断redis中是否存在断点，
>如果存在则继续爬取，否则从队列中弹出一个元素，并继续爬取。
## middleware
> 设置代理，会发送请求requests获取代理
> 设置cookie，会检测spider之前的cookie是否已经不可用，如果不可用，则重新发起请求获取
> 重写最大值重试次数中间件 功能只是添加了一个日志输出
## pipeline
> JsonPipeline 用于把解析出来的数据保存到json文件中<br>
> SavePagePipeline 保存原始的页面
